{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpYUmhrHiIR8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YftVD50iIR9"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = np.array(X)\n",
        "        self.y_train = np.array(y).astype(int)\n",
        "\n",
        "    def compute_distance(self, X_test):\n",
        "        # Vectorized Euclidean distance calculation for multiple test points\n",
        "        # Uses broadcasting to compute distance between X_test and all points in X_train\n",
        "        X_test = np.array(X_test)\n",
        "        distances = np.sqrt(np.sum((self.X_train - X_test) ** 2, axis=1))\n",
        "        return distances\n",
        "\n",
        "    def predict(self, X):\n",
        "      X = np.array(X)\n",
        "      predictions = []\n",
        "      for i in range(X.shape[0]):\n",
        "          x_test = X[i]\n",
        "          distances = self.compute_distance(x_test)\n",
        "          k_indices = np.argsort(distances)[:self.k]\n",
        "          k_nearest_labels = self.y_train[k_indices]\n",
        "          prediction = np.argmax(np.bincount(k_nearest_labels))\n",
        "          predictions.append(prediction)\n",
        "      return np.array(predictions)\n",
        "\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "      X = np.array(X)\n",
        "      probas = []\n",
        "      for i in range(X.shape[0]):\n",
        "          x_test = X[i]\n",
        "          distances = self.compute_distance(x_test)\n",
        "          k_indices = np.argsort(distances)[:self.k]\n",
        "          k_nearest_labels = self.y_train[k_indices]\n",
        "          prob_class_1 = np.sum(k_nearest_labels) / self.k\n",
        "          prob_class_0 = 1 - prob_class_1\n",
        "          probas.append([prob_class_0, prob_class_1])\n",
        "      return np.array(probas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oegmBKspiIR9"
      },
      "outputs": [],
      "source": [
        "# Define data preprocessing function\n",
        "def preprocess_data(train_path, test_path):\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    train_data = train_data.drop(columns=['id', 'CustomerId', 'Surname', 'HasCrCard', 'Tenure', 'CreditScore'])\n",
        "    test_data = test_data.drop(columns=['id', 'CustomerId', 'Surname', 'HasCrCard', 'Tenure', 'CreditScore'])\n",
        "\n",
        "    y_train = train_data['Exited']\n",
        "    train_data = train_data.drop(columns=['Exited'])\n",
        "\n",
        "    train_data, test_data = train_data.align(test_data, join='left', axis=1, fill_value=0)\n",
        "\n",
        "    train_data = pd.get_dummies(train_data, columns=['Geography', 'Gender'], drop_first=True)\n",
        "    test_data = pd.get_dummies(test_data, columns=['Geography', 'Gender'], drop_first=True)\n",
        "\n",
        "    train_data.fillna(train_data.median(), inplace=True)\n",
        "    test_data.fillna(test_data.median(), inplace=True)\n",
        "\n",
        "    train_data = train_data.astype(float)\n",
        "    test_data = test_data.astype(float)\n",
        "\n",
        "    #X_train = train_data.drop(columns=['Exited'])\n",
        "    #y_train = train_data['Exited']\n",
        "\n",
        "    X_test = test_data\n",
        "\n",
        "    X_train_scaled = (train_data - train_data.min()) / (train_data.max() - train_data.min())\n",
        "    X_test_scaled = (test_data - train_data.min()) / (train_data.max() - train_data.min())\n",
        "\n",
        "\n",
        "    scaling_factors = {\n",
        "        'Age': 1.148512,\n",
        "        'Geography_Germany': 0.597631,\n",
        "        'EstimatedSalary': 0.055690,\n",
        "        'Geography_Spain': 0.031196,\n",
        "        'Balance': 0.285098,\n",
        "        'Gender_Male': 0.406736,\n",
        "        'IsActiveMember': 0.666314,\n",
        "        'NumOfProducts': 0.689368\n",
        "    }\n",
        "\n",
        "    # Normalize the scaling factors (optional)\n",
        "    max_scaling_factor = max(abs(v) for v in scaling_factors.values())\n",
        "    normalized_scaling_factors = {k: abs(v) / max_scaling_factor for k, v in scaling_factors.items()}\n",
        "\n",
        "    # Apply scaling to each feature in the training and test data\n",
        "    for feature, factor in normalized_scaling_factors.items():\n",
        "        if feature in X_train_scaled.columns:\n",
        "            X_train_scaled[feature] *= factor\n",
        "            X_test_scaled[feature] *= factor\n",
        "\n",
        "    # Return the preprocessed and scaled data as numpy arrays\n",
        "    return X_train_scaled.to_numpy(), y_train.to_numpy(), X_test_scaled.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNXyQzVWiIR9"
      },
      "outputs": [],
      "source": [
        "# Define cross-validation function\n",
        "def roc_auc_score_np(y_true, y_prob):\n",
        "    # Sort the data based on the predicted probabilities\n",
        "    sorted_indices = np.argsort(y_prob)[::-1]\n",
        "    y_true_sorted = y_true[sorted_indices]\n",
        "\n",
        "    # Calculate True Positive and False Positive rates\n",
        "    tpr = np.cumsum(y_true_sorted) / np.sum(y_true_sorted)\n",
        "    fpr = np.cumsum(1 - y_true_sorted) / np.sum(1 - y_true_sorted)\n",
        "\n",
        "    # Add (0, 0) at the beginning of the curve\n",
        "    tpr = np.concatenate([[0], tpr])\n",
        "    fpr = np.concatenate([[0], fpr])\n",
        "\n",
        "    # Calculate AUC as the area under the curve using the trapezoidal rule\n",
        "    auc = np.trapz(tpr, fpr)\n",
        "    return auc\n",
        "\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    # Convert DataFrames to numpy arrays\n",
        "\n",
        "\n",
        "    # Shuffle the data indices\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    # Split the indices into n_splits roughly equal parts\n",
        "    fold_size = X.shape[0] // n_splits\n",
        "    auc_scores = []\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        # Determine test indices for this fold\n",
        "        test_indices = indices[i * fold_size:(i + 1) * fold_size]\n",
        "\n",
        "        # The rest are the training indices\n",
        "        train_indices = np.setdiff1d(indices, test_indices)\n",
        "\n",
        "        # Split the data into training and test sets\n",
        "        X_train, y_train = X[train_indices], y[train_indices]\n",
        "        X_test, y_test = X[test_indices], y[test_indices]\n",
        "\n",
        "        # Train the K-NN model\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Predict probabilities for the test set (positive class = 1)\n",
        "        y_prob = knn.predict_proba(X_test)[:, 1]\n",
        "\n",
        "        # Calculate the ROC AUC score for this fold using the helper function\n",
        "        auc = roc_auc_score_np(y_test, y_prob)\n",
        "        auc_scores.append(auc)\n",
        "\n",
        "    # Return the average ROC AUC score across all folds\n",
        "    return np.mean(auc_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCnxVxywiIR9",
        "outputId": "bd3951e1-ee3d-4536-d2f4-82f1a5278986"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: 0.8873008031725792\n",
            "k: 24, AUC: 0.9195204345953838\n",
            "Best hyperparameters: k = 24\n",
            "Best AUC: 0.9195204345953838\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('/content/train.csv', '/content/test.csv')\n",
        "\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "# TODO: hyperparamters tuning\n",
        "\n",
        "def hyperparameter_tuning(X, y, n_splits=5):\n",
        "\n",
        "\n",
        "\n",
        "    best_auc = 0\n",
        "    best_params = {'k': None}\n",
        "\n",
        "    # Define the hyperparameter grid to search\n",
        "    k_values = [24]  # Different values of k (number of neighbors)\n",
        "\n",
        "    # Iterate over all values of k\n",
        "    for k in k_values:\n",
        "        # Initialize a K-NN model with the current value of k and Euclidean distance\n",
        "        knn = KNN(k=k, distance_metric='euclidean')\n",
        "\n",
        "        # Perform cross-validation and get the average AUC score\n",
        "        auc_score = cross_validate(X, y, knn, n_splits=n_splits)\n",
        "        print(f\"k: {k}, AUC: {auc_score}\")\n",
        "\n",
        "        # Check if this is the best score so far\n",
        "        if auc_score > best_auc:\n",
        "            best_auc = auc_score\n",
        "            best_params = {'k': k}\n",
        "\n",
        "    print(f\"Best hyperparameters: k = {best_params['k']}\")\n",
        "    print(f\"Best AUC: {best_auc}\")\n",
        "    return best_params\n",
        "\n",
        "\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "best_params = hyperparameter_tuning(X, y)\n",
        "\n",
        "# Train the model with the best hyperparameters on the full dataset\n",
        "knn = KNN(k=best_params['k'])\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('/content/test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions3.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}